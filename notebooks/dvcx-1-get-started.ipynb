{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "import easyocr\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import dvcx\n",
    "from dvcx.query import C, DatasetQuery, udf\n",
    "from dvcx.lib.dataset import Dataset\n",
    "\n",
    "os.environ['AWS_PROFILE']='iterative-sandbox'\n",
    "print(os.environ['AWS_PROFILE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 1 - Create/Add a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WILDRECEIPT_S3 = \"s3://cse-dvcx-public/example-dvcx-ocr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List files \n",
    "ds = (DatasetQuery(path=WILDRECEIPT_S3)\n",
    "      .filter(C.name.endswith(\".jpeg\"))\n",
    "     )\n",
    "\n",
    "ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset Sample (filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_ocr = (ds\n",
    " # .filter(C.name.glob(\"*.jpeg\"))\n",
    ")\n",
    "ds_ocr.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata (from .txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dvcx.query import udf, C, DatasetQuery\n",
    "# from sqlalchemy import Integer\n",
    "\n",
    "\n",
    "# @udf(\n",
    "#     output={\"path_len\": Integer},\n",
    "#     params=(C.parent, C.name),\n",
    "#     batch=10,\n",
    "# )\n",
    "# def name_len(names):\n",
    "#     print(type(names))\n",
    "#     return [(len(parent + name),) for (parent, name) in names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Add a signal with funciton-based UDF\n",
    "# ds_with_name_len = ds_ocr.add_signals(name_len)\n",
    "# ds_with_name_len.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = (\n",
    "    Dataset(\n",
    "        WILDRECEIPT_S3,\n",
    "        # client_config={\"aws_anon\": True},\n",
    "    )\n",
    "    # .filter(C.name.glob(\"*.pdf\"))\n",
    "    .limit(10)\n",
    "    # .map(PartitionObject(), parallel=False)\n",
    ")\n",
    "ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Integer\n",
    "\n",
    "def count(parent):\n",
    "    return (len(parent),)\n",
    "\n",
    "ds.map(count, output={\"length\": Integer}).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Text\n",
    "\n",
    "# Use `.map` \n",
    "\n",
    "def add_file_name(parent, name):\n",
    "    path_in_medatata = []\n",
    "    path = parent.strip('/') + '/' + name\n",
    "    path = path.replace('example-dvcx-ocr/wildreceipt/', '')\n",
    "\n",
    "    return (path,)\n",
    "\n",
    "ds.map(add_file_name, output={\"file_name\": Text}).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Use UDF\n",
    "\n",
    "\n",
    "# from sqlalchemy import Text\n",
    "\n",
    "# @udf(\n",
    "#     output={\"file_name\": Text},\n",
    "#     params=(C.parent, C.name),\n",
    "#     batch=10,\n",
    "# )\n",
    "# def add_file_name(params):\n",
    "#     path_in_medatata = []\n",
    "    \n",
    "    \n",
    "#     for parent, name in params: \n",
    "#         # print(parent, name)\n",
    "#         path = parent.strip('/') + '/' + name\n",
    "#         path = path.replace('example-dvcx-ocr/wildreceipt/', '')\n",
    "#         # print(path)\n",
    "#         path_in_medatata.append( (path, ) )  # Why it should be a tuple here? \n",
    "#     return path_in_medatata \n",
    "\n",
    "# ds_with_name_len = ds_ocr.add_signals(add_file_name)\n",
    "# ds_with_name_len.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# File path\n",
    "file_path = '../data/wildreceipt/train.txt'\n",
    "\n",
    "# Read JSON data from file\n",
    "meta = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        meta.append(json.loads(line.strip()))\n",
    "\n",
    "len(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for file in meta[:100]:\n",
    "#     if file.get('file_name', '') == 'image_files/Image_16/11/d5de7f2a20751e50b84c747c17a24cd98bed3554.jpeg':\n",
    "#         print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def add_annotations(file_name):\n",
    "\n",
    "    # Read JSON data from file\n",
    "    file_path = '../data/wildreceipt/train.txt'\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            meta = json.loads(line.strip())\n",
    "            if meta.get('file_name', '') == file_name:\n",
    "                # print(file_name)\n",
    "                # res = file\n",
    "                break\n",
    "\n",
    "    return (meta['height'], meta['width'], str(meta['annotations']),)\n",
    "\n",
    "\n",
    "ds = (Dataset(WILDRECEIPT_S3)\n",
    "    .filter(C.name.glob(\"*.jpeg\"))\n",
    "    .limit(100)\n",
    "    # .map(PartitionObject(), parallel=False)\n",
    ")\n",
    "\n",
    "ds = ds.map(add_file_name, output={\"file_name\": Text})\n",
    "ds = ds.map(add_annotations, output={\"height\": Integer, \"width\": Integer, \"annotations\":Text})\n",
    "ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save('wildreceipt-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvcx.cli import ls_datasets, get_catalog\n",
    "\n",
    "ls_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat = get_catalog()\n",
    "cat.get_dataset('wildreceipt-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = cat.get_dataset('wildreceipt-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dvcx.dataset import create_dataset_uri\n",
    "\n",
    "create_dataset_uri('wildreceipt-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = Dataset('ds://wildreceipt-train')\n",
    "ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sqlalchemy import Text\n",
    "\n",
    "# @udf(\n",
    "#     output=(\n",
    "#         (\"height\", Integer),\n",
    "#         # \"width\": Integer,\n",
    "#         # \"annotations\": Text,\n",
    "#     ),\n",
    "#     params=(C.file_name),\n",
    "#     batch=10,\n",
    "# )\n",
    "# def add_annotations(params):\n",
    "\n",
    "#     # File path\n",
    "#     file_path = '../data/wildreceipt/train.txt'\n",
    "    \n",
    "#     # Read JSON data from file\n",
    "#     meta = []\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             meta.append(json.loads(line.strip()))\n",
    "#     print(len(meta))\n",
    "    \n",
    "#     metadata = [] \n",
    "#     for path in params: \n",
    "#         print(path)\n",
    "        \n",
    "#         for file in meta:\n",
    "\n",
    "#             print(file)\n",
    "            \n",
    "#             if file.get('file_name', '') == path:\n",
    "#                 print(path)\n",
    "#                 metadata.append(\n",
    "#                     (\n",
    "#                         file.get('height', ''), \n",
    "#                         # file.get('width', ''), \n",
    "#                         # str(file.get('annotations', '')),\n",
    "#                     )\n",
    "#                 )\n",
    "    \n",
    "#     return metadata\n",
    "\n",
    "# ds_with_name_meta = ds_with_name_len.add_signals(add_annotations)\n",
    "# ds_with_name_meta.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect text - OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageOps, UnidentifiedImageError\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\n",
    "        \"Missing dependency Pillow for computer vision:\\n\"\n",
    "        \"To install run:\\n\\n\"\n",
    "        \"  pip install 'dvcx[cv]'\\n\"\n",
    "    ) from exc\n",
    "\n",
    "from dvcx.query import Object, udf\n",
    "from dvcx.sql.types import String\n",
    "\n",
    "def encode_image(raw):\n",
    "    try:\n",
    "        img = Image.open(raw)\n",
    "    except UnidentifiedImageError:\n",
    "        return None\n",
    "    img.load()\n",
    "    # img = img.convert(\"RGB\")\n",
    "    # img = ImageOps.fit(img, DEFAULT_FIT_BOX)\n",
    "    return img\n",
    "\n",
    "\n",
    "@udf(\n",
    "    params=(parent: Text,),  # Columns consumed by the UDF.\n",
    "    output={\n",
    "        \"ocr\": String,\n",
    "    },  # Signals being returned by the UDF.\n",
    "    method=\"process\",\n",
    ")\n",
    "class OpenImageDetect:\n",
    "    def __init__(self):\n",
    "        self.model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)\n",
    "\n",
    "    def process(self, ):\n",
    "\n",
    "        print(img)\n",
    "\n",
    "        # with stream_jpg.open() as fd:\n",
    "        #     img = Image.open(fd)\n",
    "\n",
    "        print(self.model)\n",
    "        doc = DocumentFile.from_images(fd)\n",
    "        result = model(doc)\n",
    "\n",
    "        return (result, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = (Dataset(WILDRECEIPT_S3)\n",
    "    .filter(C.name.glob(\"*.jpeg\"))\n",
    "    .limit(100)\n",
    "    # .map(PartitionObject(), parallel=False)\n",
    ")\n",
    "\n",
    "ds = ds.map(add_file_name, output={\"file_name\": Text})\n",
    "ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process(img):\n",
    "\n",
    "    print(img)\n",
    "\n",
    "    # with stream_jpg.open() as fd:\n",
    "    #     img = Image.open(fd)\n",
    "\n",
    "    print(self.model)\n",
    "    doc = DocumentFile.from_images(fd)\n",
    "    result = model(doc)\n",
    "\n",
    "    return (result, )\n",
    "\n",
    "ds = ds.map\n",
    "    .aggregate(\n",
    "        OpenImageDetect(),\n",
    "        # partition_by=path.file_stem(C.name),\n",
    "    )\n",
    ")\n",
    "\n",
    "ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE → OCR Engine -> Text Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(raw):\n",
    "    # img = Image.open(raw)\n",
    "    # img.load()\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Process / Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Extractions with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text boxes → LLM → JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
